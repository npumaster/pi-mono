# GLM-4.5

[ä¸­æ–‡é˜…è¯»](./README_zh.md)

<div align="center">
<img src=resources/logo.svg width="15%"/>
</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="resources/WECHAT.md" target="_blank">å¾®ä¿¡</a> æˆ– <a href="https://discord.gg/QR7SARHRxK" target="_blank">Discord</a> ç¤¾åŒºã€‚
    <br>
    ğŸ“– æŸ¥çœ‹ GLM-4.5 <a href="https://z.ai/blog/glm-4.5" target="_blank">æŠ€æœ¯åšå®¢</a>ã€‚
    <br>
    ğŸ“ åœ¨ <a href="https://docs.z.ai/guides/llm/glm-4.5">Z.ai API å¹³å° (å…¨çƒ)</a> æˆ– <br> <a href="https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5">æ™ºè°± AI å¼€æ”¾å¹³å° (ä¸­å›½å¤§é™†)</a> ä¸Šä½¿ç”¨ GLM-4.5 API æœåŠ¡ã€‚
    <br>
    ğŸ‘‰ ä¸€é”®ç›´è¾¾ <a href="https://chat.z.ai">GLM-4.5</a>ã€‚
</p>

## æ¨¡å‹ä»‹ç»

**GLM-4.5** ç³»åˆ—æ¨¡å‹æ˜¯ä¸ºæ™ºèƒ½ä½“è®¾è®¡çš„åŸºç¡€æ¨¡å‹ã€‚GLM-4.5 æ€»å…±æœ‰ **355** äº¿å‚æ•°ï¼Œå…¶ä¸­ **32** äº¿æ¿€æ´»å‚æ•°ï¼Œè€Œ GLM-4.5-Air é‡‡ç”¨æ›´ç´§å‡‘çš„è®¾è®¡ï¼Œæ€»å…±æœ‰ **106** äº¿å‚æ•°ï¼Œå…¶ä¸­ **12** äº¿æ¿€æ´»å‚æ•°ã€‚GLM-4.5 æ¨¡å‹ç»Ÿä¸€äº†æ¨ç†ã€ç¼–ç å’Œæ™ºèƒ½ä½“èƒ½åŠ›ï¼Œä»¥æ»¡è¶³æ™ºèƒ½ä½“åº”ç”¨çš„å¤æ‚éœ€æ±‚ã€‚

GLM-4.5 å’Œ GLM-4.5-Air éƒ½æ˜¯æ··åˆæ¨ç†æ¨¡å‹ï¼Œæä¾›ä¸¤ç§æ¨¡å¼ï¼šç”¨äºå¤æ‚æ¨ç†å’Œå·¥å…·ä½¿ç”¨çš„æ€è€ƒæ¨¡å¼ï¼Œä»¥åŠç”¨äºç«‹å³å“åº”çš„éæ€è€ƒæ¨¡å¼ã€‚

æˆ‘ä»¬å·²ç»å¼€æºäº† GLM-4.5 å’Œ GLM-4.5-Air çš„åŸºç¡€æ¨¡å‹ã€æ··åˆæ¨ç†æ¨¡å‹ä»¥åŠæ··åˆæ¨ç†æ¨¡å‹çš„ FP8 ç‰ˆæœ¬ã€‚å®ƒä»¬åœ¨ MIT å¼€æºè®¸å¯è¯ä¸‹å‘å¸ƒï¼Œå¯ä»¥è¿›è¡Œå•†ä¸šä½¿ç”¨å’ŒäºŒæ¬¡å¼€å‘ã€‚

æ­£å¦‚æˆ‘ä»¬åœ¨ 12 ä¸ªè¡Œä¸šæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­çš„ç»¼åˆè¯„ä¼°æ‰€ç¤ºï¼ŒGLM-4.5 å–å¾—äº† **63.2** çš„ä¼˜å¼‚æˆç»©ï¼Œåœ¨æ‰€æœ‰ä¸“æœ‰å’Œå¼€æºæ¨¡å‹ä¸­æ’å **ç¬¬ 3**ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGLM-4.5-Air åœ¨ä¿æŒå“è¶Šæ•ˆç‡çš„åŒæ—¶ï¼Œä¹Ÿæä¾›äº†æå…·ç«äº‰åŠ›çš„ç»“æœï¼Œå¾—åˆ†ä¸º **59.8**ã€‚

![bench](resources/bench.png)

æœ‰å…³æ›´å¤šè¯„ä¼°ç»“æœã€å±•ç¤ºæ¡ˆä¾‹å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„ [æŠ€æœ¯åšå®¢](https://z.ai/blog/glm-4.5)ã€‚æŠ€æœ¯æŠ¥å‘Šå³å°†å‘å¸ƒã€‚

æ¨¡å‹ä»£ç ã€å·¥å…·è§£æå™¨å’Œæ¨ç†è§£æå™¨å¯ä»¥åœ¨ [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4_moe)ã€[vLLM](https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/glm4_moe_mtp.py) å’Œ [SGLang](https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/models/glm4_moe.py) çš„å®ç°ä¸­æ‰¾åˆ°ã€‚

## æ¨¡å‹ä¸‹è½½

ä½ å¯ä»¥ç›´æ¥åœ¨ [Hugging Face](https://huggingface.co/spaces/zai-org/GLM-4.5-Space) æˆ– [ModelScope](https://modelscope.cn/studios/ZhipuAI/GLM-4.5-Demo) ä¸Šä½“éªŒè¯¥æ¨¡å‹ï¼Œæˆ–è€…é€šè¿‡ä»¥ä¸‹é“¾æ¥ä¸‹è½½æ¨¡å‹ã€‚

| æ¨¡å‹ | ä¸‹è½½é“¾æ¥ | æ¨¡å‹å¤§å° | ç²¾åº¦ |
|---|---|---|---|
| GLM-4.5 | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5) | 355B-A32B | BF16 |
| GLM-4.5-Air | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air) | 106B-A12B | BF16 |
| GLM-4.5-FP8 | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-FP8)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-FP8) | 355B-A32B | FP8 |
| GLM-4.5-Air-FP8 | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air-FP8)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-FP8) | 106B-A12B | FP8 |
| GLM-4.5-Base | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Base) | 355B-A32B | BF16 |
| GLM-4.5-Air-Base | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-Base) | 106B-A12B | BF16 |

## ç³»ç»Ÿè¦æ±‚

### æ¨ç†

æˆ‘ä»¬ä¸ºâ€œå…¨åŠŸèƒ½â€æ¨¡å‹æ¨ç†æä¾›æœ€ä½å’Œæ¨èé…ç½®ã€‚ä¸‹è¡¨ä¸­çš„æ•°æ®åŸºäºä»¥ä¸‹æ¡ä»¶ï¼š

1. æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ MTP å±‚å¹¶æŒ‡å®š `--speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4` ä»¥ç¡®ä¿å…·æœ‰ç«äº‰åŠ›çš„æ¨ç†é€Ÿåº¦ã€‚
2. ä¸ä½¿ç”¨ `cpu-offload` å‚æ•°ã€‚
3. æ¨ç†æ‰¹å¤„ç†å¤§å°ä¸è¶…è¿‡ `8`ã€‚
4. å…¨éƒ¨åœ¨åŸç”Ÿæ”¯æŒ FP8 æ¨ç†çš„è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œç¡®ä¿æƒé‡å’Œç¼“å­˜å‡ä¸º FP8 æ ¼å¼ã€‚
5. æœåŠ¡å™¨å†…å­˜å¿…é¡»è¶…è¿‡ `1T` ä»¥ç¡®ä¿æ¨¡å‹æ­£å¸¸åŠ è½½å’Œè¿è¡Œã€‚

æ¨¡å‹å¯ä»¥åœ¨ä¸‹è¡¨ä¸­çš„é…ç½®ä¸‹è¿è¡Œï¼š

| æ¨¡å‹ | ç²¾åº¦ | GPU ç±»å‹å’Œæ•°é‡ | æµ‹è¯•æ¡†æ¶ |
|---|---|---|---|
| GLM-4.5 | BF16 | H100 x 16 / H200 x 8 | sglang |
| GLM-4.5 | FP8 | H100 x 8 / H200 x 4 | sglang |
| GLM-4.5-Air | BF16 | H100 x 4 / H200 x 2 | sglang |
| GLM-4.5-Air | FP8 | H100 x 2 / H200 x 1 | sglang |

åœ¨ä¸‹è¡¨ä¸­çš„é…ç½®ä¸‹ï¼Œæ¨¡å‹å¯ä»¥åˆ©ç”¨å…¶å®Œæ•´çš„ 128K ä¸Šä¸‹æ–‡é•¿åº¦ï¼š

| æ¨¡å‹ | ç²¾åº¦ | GPU ç±»å‹å’Œæ•°é‡ | æµ‹è¯•æ¡†æ¶ |
|---|---|---|---|
| GLM-4.5 | BF16 | H100 x 32 / H200 x 16 | sglang |
| GLM-4.5 | FP8 | H100 x 16 / H200 x 8 | sglang |
| GLM-4.5-Air | BF16 | H100 x 8 / H200 x 4 | sglang |
| GLM-4.5-Air | FP8 | H100 x 4 / H200 x 2 | sglang |

### å¾®è°ƒ

ä»£ç å¯ä»¥åœ¨ä¸‹è¡¨ä¸­çš„é…ç½®ä¸‹ä½¿ç”¨ [Llama Factory](https://github.com/hiyouga/LLaMA-Factory) è¿è¡Œï¼š

| æ¨¡å‹ | GPU ç±»å‹å’Œæ•°é‡ | ç­–ç•¥ | æ‰¹å¤„ç†å¤§å° (æ¯ä¸ª GPU) |
|---|---|---|---|
| GLM-4.5 | H100 x 16 | Lora | 1 |
| GLM-4.5-Air | H100 x 4 | Lora | 1 |

ä»£ç å¯ä»¥åœ¨ä¸‹è¡¨ä¸­çš„é…ç½®ä¸‹ä½¿ç”¨ [Swift](https://github.com/modelscope/ms-swift) è¿è¡Œï¼š

| æ¨¡å‹ | GPU ç±»å‹å’Œæ•°é‡ | ç­–ç•¥ | æ‰¹å¤„ç†å¤§å° (æ¯ä¸ª GPU) |
|---|---|---|---|
| GLM-4.5 | H20 (96GiB) x 16 | Lora | 1 |
| GLM-4.5-Air | H20 (96GiB) x 4 | Lora | 1 |
| GLM-4.5 | H20 (96GiB) x 128 | SFT | 1 |
| GLM-4.5-Air | H20 (96GiB) x 32 | SFT | 1 |
| GLM-4.5 | H20 (96GiB) x 128 | RL | 1 |
| GLM-4.5-Air | H20 (96GiB) x 32 | RL | 1 |

## å¿«é€Ÿå¼€å§‹

è¯·æ ¹æ® `requirements.txt` å®‰è£…æ‰€éœ€çš„åŒ…ã€‚

```shell
pip install -r requirements.txt
```

### transformers

è¯·å‚è€ƒ `inference` æ–‡ä»¶å¤¹ä¸­çš„ `trans_infer_cli.py` ä»£ç ã€‚

### vLLM

+ BF16 å’Œ FP8 éƒ½å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å¯åŠ¨ï¼š

```shell
vllm serve zai-org/GLM-4.5-Air \
    --tensor-parallel-size 8 \
    --tool-call-parser glm45 \
    --reasoning-parser glm45 \
    --enable-auto-tool-choice \
    --served-model-name glm-4.5-air
```

å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ 8x H100 GPU å¹¶åœ¨è¿è¡Œ GLM-4.5 æ¨¡å‹æ—¶é‡åˆ°å†…å­˜ä¸è¶³ï¼Œä½ å°†éœ€è¦ `--cpu-offload-gb 16`ï¼ˆä»…é€‚ç”¨äº vLLMï¼‰ã€‚

å¦‚æœä½ é‡åˆ° `flash infer` é—®é¢˜ï¼Œè¯·ä½¿ç”¨ `VLLM_ATTENTION_BACKEND=XFORMERS` ä½œä¸ºä¸´æ—¶æ›¿æ¢ã€‚ä½ ä¹Ÿå¯ä»¥æŒ‡å®š `TORCH_CUDA_ARCH_LIST='9.0+PTX'` æ¥ä½¿ç”¨ `flash infer`ï¼ˆä¸åŒçš„ GPU æœ‰ä¸åŒçš„ TORCH_CUDA_ARCH_LIST å€¼ï¼Œè¯·ç›¸åº”æ£€æŸ¥ï¼‰ã€‚

### SGLang

+ BF16

```shell
python3 -m sglang.launch_server \
  --model-path zai-org/GLM-4.5-Air \
  --tp-size 8 \
  --tool-call-parser glm45  \
  --reasoning-parser glm45 \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3 \
  --speculative-eagle-topk 1 \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.7 \
  --served-model-name glm-4.5-air \
  --host 0.0.0.0 \
  --port 8000
```

+ FP8

```shell
python3 -m sglang.launch_server \
  --model-path zai-org/GLM-4.5-Air-FP8 \
  --tp-size 4 \
  --tool-call-parser glm45  \
  --reasoning-parser glm45  \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3  \
  --speculative-eagle-topk 1  \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.7 \
  --disable-shared-experts-fusion \
  --served-model-name glm-4.5-air-fp8 \
  --host 0.0.0.0 \
  --port 8000
```

### è¯·æ±‚å‚æ•°è¯´æ˜

+ å½“ä½¿ç”¨ `vLLM` å’Œ `SGLang` æ—¶ï¼Œå‘é€è¯·æ±‚æ—¶é»˜è®¤å¯ç”¨æ€è€ƒæ¨¡å¼ã€‚å¦‚æœä½ æƒ³ç¦ç”¨æ€è€ƒå¼€å…³ï¼Œä½ éœ€è¦æ·»åŠ  `extra_body={"chat_template_kwargs": {"enable_thinking": False}}` å‚æ•°ã€‚
+ ä¸¤è€…éƒ½æ”¯æŒå·¥å…·è°ƒç”¨ã€‚è¯·ä½¿ç”¨ OpenAI é£æ ¼çš„å·¥å…·æè¿°æ ¼å¼è¿›è¡Œè°ƒç”¨ã€‚
+ å…·ä½“ä»£ç ï¼Œè¯·å‚è€ƒ `inference` æ–‡ä»¶å¤¹ä¸­çš„ `api_request.py`ã€‚
